{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# License Plate Recognition Training - YOLOv8\n",
                "\n",
                "Training model untuk OCR karakter plat nomor di server.\n",
                "\n",
                "**Dataset**: Indonesian License Plate Recognition Dataset (~1900 images)\n",
                "\n",
                "**Classes**: 37 (0-9, A-Z)\n",
                "\n",
                "**Model**: YOLOv8 (lebih akurat untuk server dengan resource cukup)\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_REPO/license-plate-recognition-training.ipynb)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸš€ Google Colab Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check if running on Google Colab\n",
                "import sys\n",
                "IN_COLAB = 'google.colab' in sys.modules\n",
                "\n",
                "if IN_COLAB:\n",
                "    print(\"âœ“ Running on Google Colab\")\n",
                "    # Check GPU\n",
                "    !nvidia-smi\n",
                "else:\n",
                "    print(\"âœ“ Running locally\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install ultralytics (YOLOv8)\n",
                "!pip install -q ultralytics kagglehub\n",
                "!pip install -q opencv-python matplotlib pillow pyyaml tqdm pandas scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import yaml\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "import glob\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image, ImageDraw, ImageFont\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from ultralytics import YOLO\n",
                "import cv2\n",
                "import kagglehub\n",
                "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
                "from collections import Counter\n",
                "import time\n",
                "\n",
                "print(\"âœ“ Environment setup complete!\")\n",
                "print(f\"Ultralytics version: {__import__('ultralytics').__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download Dataset from Kaggle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download Indonesian License Plate Recognition Dataset\n",
                "# Note: Gunakan dataset yang sama atau dataset khusus untuk recognition jika ada\n",
                "print(\"Downloading Indonesian License Plate Dataset from Kaggle...\")\n",
                "path = kagglehub.dataset_download(\"juanthomaswijaya/indonesian-license-plate-dataset\")\n",
                "\n",
                "print(f\"âœ“ Dataset downloaded to: {path}\")\n",
                "DATASET_ROOT = Path(path)\n",
                "\n",
                "# Cari folder Indonesian License Plate Recognition Dataset\n",
                "# Adjust path based on actual dataset structure\n",
                "recognition_dataset_candidates = list(DATASET_ROOT.glob('**/Indonesian License Plate Recognition Dataset'))\n",
                "if recognition_dataset_candidates:\n",
                "    DATASET_ROOT = recognition_dataset_candidates[0]\n",
                "    print(f\"Found recognition dataset at: {DATASET_ROOT}\")\n",
                "else:\n",
                "    print(\"Recognition dataset not found in expected location.\")\n",
                "    print(\"Available directories:\")\n",
                "    for item in DATASET_ROOT.rglob('*'):\n",
                "        if item.is_dir():\n",
                "            print(f\"  {item}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Dataset Exploration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset paths\n",
                "IMAGES_DIR = DATASET_ROOT / 'images'\n",
                "LABELS_DIR = DATASET_ROOT / 'labels'\n",
                "classes_file = DATASET_ROOT / 'classes.names'\n",
                "\n",
                "# Load class names\n",
                "if classes_file.exists():\n",
                "    with open(classes_file, 'r') as f:\n",
                "        class_names = [line.strip() for line in f.readlines()]\n",
                "else:\n",
                "    # Default class names untuk Indonesian plates\n",
                "    class_names = [str(i) for i in range(10)] + [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
                "    print(\"âš ï¸  classes.names file not found, using default 0-9, A-Z\")\n",
                "\n",
                "print(f\"Dataset root: {DATASET_ROOT.exists()}\")\n",
                "print(f\"\\nNumber of classes: {len(class_names)}\")\n",
                "print(f\"Classes: {class_names}\")\n",
                "\n",
                "# Count images\n",
                "train_images = list((IMAGES_DIR / 'train').glob('*.jpg')) + list((IMAGES_DIR / 'train').glob('*.png'))\n",
                "val_images = list((IMAGES_DIR / 'val').glob('*.jpg')) + list((IMAGES_DIR / 'val').glob('*.png'))\n",
                "test_images = list((IMAGES_DIR / 'test').glob('*.jpg')) + list((IMAGES_DIR / 'test').glob('*.png'))\n",
                "\n",
                "print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
                "print(f\"{'='*40}\")\n",
                "print(f\"Train images: {len(train_images):>6}\")\n",
                "print(f\"Val images:   {len(val_images):>6}\")\n",
                "print(f\"Test images:  {len(test_images):>6}\")\n",
                "print(f\"{'='*40}\")\n",
                "print(f\"Total:        {len(train_images) + len(val_images) + len(test_images):>6}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize samples with character annotations\n",
                "def visualize_ocr_samples(image_paths, label_dir, class_names, num_samples=4):\n",
                "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
                "    axes = axes.ravel()\n",
                "    \n",
                "    samples = np.random.choice(image_paths, min(num_samples, len(image_paths)), replace=False)\n",
                "    \n",
                "    for idx, img_path in enumerate(samples):\n",
                "        img = Image.open(img_path).convert('RGB')\n",
                "        img_array = np.array(img)\n",
                "        img_w, img_h = img.size\n",
                "        \n",
                "        # Find label file\n",
                "        label_file = label_dir / (img_path.stem + '.txt')\n",
                "        \n",
                "        # Draw on image\n",
                "        draw_img = img_array.copy()\n",
                "        \n",
                "        if label_file.exists():\n",
                "            with open(label_file, 'r') as f:\n",
                "                for line in f.readlines():\n",
                "                    parts = line.strip().split()\n",
                "                    if len(parts) < 5:\n",
                "                        continue\n",
                "                    \n",
                "                    class_id = int(parts[0])\n",
                "                    x_center, y_center, width, height = map(float, parts[1:5])\n",
                "                    \n",
                "                    # Convert to pixels\n",
                "                    x_center *= img_w\n",
                "                    y_center *= img_h\n",
                "                    width *= img_w\n",
                "                    height *= img_h\n",
                "                    \n",
                "                    x1 = int(x_center - width / 2)\n",
                "                    y1 = int(y_center - height / 2)\n",
                "                    x2 = int(x_center + width / 2)\n",
                "                    y2 = int(y_center + height / 2)\n",
                "                    \n",
                "                    # Draw rectangle\n",
                "                    cv2.rectangle(draw_img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
                "                    \n",
                "                    # Draw label\n",
                "                    label = class_names[class_id] if class_id < len(class_names) else str(class_id)\n",
                "                    cv2.putText(draw_img, label, (x1, y1-5), \n",
                "                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
                "        \n",
                "        axes[idx].imshow(draw_img)\n",
                "        axes[idx].axis('off')\n",
                "        axes[idx].set_title(f'{img_path.name}', fontsize=10)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Visualize training samples\n",
                "print(\"ðŸ“¸ Training Data Samples with Character Annotations:\")\n",
                "visualize_ocr_samples(train_images, LABELS_DIR / 'train', class_names)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze class distribution\n",
                "def count_class_distribution(label_dir):\n",
                "    class_counts = Counter()\n",
                "    label_files = list(label_dir.glob('*.txt'))\n",
                "    \n",
                "    for label_file in label_files:\n",
                "        with open(label_file, 'r') as f:\n",
                "            for line in f.readlines():\n",
                "                parts = line.strip().split()\n",
                "                if len(parts) >= 5:\n",
                "                    class_id = int(parts[0])\n",
                "                    class_counts[class_id] += 1\n",
                "    \n",
                "    return class_counts\n",
                "\n",
                "train_class_counts = count_class_distribution(LABELS_DIR / 'train')\n",
                "\n",
                "# Plot distribution\n",
                "fig, ax = plt.subplots(figsize=(16, 6))\n",
                "classes = sorted(train_class_counts.keys())\n",
                "counts = [train_class_counts[c] for c in classes]\n",
                "labels = [class_names[c] if c < len(class_names) else str(c) for c in classes]\n",
                "\n",
                "bars = ax.bar(labels, counts, color='steelblue', edgecolor='black')\n",
                "ax.set_xlabel('Character Class', fontsize=12)\n",
                "ax.set_ylabel('Count', fontsize=12)\n",
                "ax.set_title('Character Distribution in Training Set', fontsize=14, weight='bold')\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.grid(axis='y', alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nðŸ“Š Class Distribution Statistics:\")\n",
                "print(f\"{'='*40}\")\n",
                "print(f\"Total characters: {sum(counts):,}\")\n",
                "print(f\"Most common: {class_names[classes[counts.index(max(counts))]]} ({max(counts):,} instances)\")\n",
                "print(f\"Least common: {class_names[classes[counts.index(min(counts))]]} ({min(counts):,} instances)\")\n",
                "print(f\"Average per class: {sum(counts)/len(counts):.1f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Create YOLOv8 Dataset Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create dataset.yaml for YOLOv8\n",
                "dataset_yaml = {\n",
                "    'path': str(DATASET_ROOT.absolute()),\n",
                "    'train': 'images/train',\n",
                "    'val': 'images/val',\n",
                "    'test': 'images/test',\n",
                "    'nc': len(class_names),\n",
                "    'names': class_names\n",
                "}\n",
                "\n",
                "yaml_path = 'license_plate_recognition.yaml'\n",
                "with open(yaml_path, 'w') as f:\n",
                "    yaml.dump(dataset_yaml, f, sort_keys=False)\n",
                "\n",
                "print(f\"âœ“ Dataset config saved to: {yaml_path}\")\n",
                "print(\"\\nContent:\")\n",
                "with open(yaml_path, 'r') as f:\n",
                "    content = f.read()\n",
                "    # Show truncated version if too long\n",
                "    lines = content.split('\\n')\n",
                "    if len(lines) > 15:\n",
                "        print('\\n'.join(lines[:10]))\n",
                "        print(f\"... ({len(lines)-15} more lines)\")\n",
                "        print('\\n'.join(lines[-5:]))\n",
                "    else:\n",
                "        print(content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train YOLOv8 Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training configuration\n",
                "MODEL = 'yolov8n'  # nano model (untuk balance speed & accuracy)\n",
                "# Alternative: yolov8s, yolov8m untuk akurasi lebih tinggi\n",
                "\n",
                "EPOCHS = 150\n",
                "BATCH_SIZE = 16 if IN_COLAB else 8\n",
                "IMG_SIZE = 640\n",
                "PROJECT = 'runs/ocr'\n",
                "NAME = 'license_plate_recognition'\n",
                "\n",
                "print(f\"ðŸ”§ Training Configuration:\")\n",
                "print(f\"{'='*40}\")\n",
                "print(f\"Model:       {MODEL}\")\n",
                "print(f\"Epochs:      {EPOCHS}\")\n",
                "print(f\"Batch size:  {BATCH_SIZE}\")\n",
                "print(f\"Image size:  {IMG_SIZE}\")\n",
                "print(f\"Classes:     {len(class_names)} (0-9, A-Z)\")\n",
                "print(f\"Device:      {'GPU (Colab)' if IN_COLAB else 'CPU/GPU'}\")\n",
                "print(f\"{'='*40}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize model\n",
                "model = YOLO(f'{MODEL}.pt')\n",
                "\n",
                "# Train\n",
                "print(\"\\nðŸš€ Starting training...\\n\")\n",
                "results = model.train(\n",
                "    data=yaml_path,\n",
                "    epochs=EPOCHS,\n",
                "    imgsz=IMG_SIZE,\n",
                "    batch=BATCH_SIZE,\n",
                "    project=PROJECT,\n",
                "    name=NAME,\n",
                "    patience=30,\n",
                "    save=True,\n",
                "    cache=True,\n",
                "    plots=True,\n",
                "    verbose=True\n",
                ")\n",
                "\n",
                "print(\"\\nâœ“ Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Comprehensive Model Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "best_model_path = Path(PROJECT) / NAME / 'weights' / 'best.pt'\n",
                "model = YOLO(str(best_model_path))\n",
                "\n",
                "print(f\"âœ“ Loaded best model from: {best_model_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate on test set\n",
                "print(\"\\nðŸ§ª Testing on TEST SET...\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "metrics = model.val(\n",
                "    data=yaml_path,\n",
                "    split='test',\n",
                "    imgsz=IMG_SIZE,\n",
                "    plots=True,\n",
                "    save_json=True,\n",
                "    verbose=True\n",
                ")\n",
                "\n",
                "print(\"\\nðŸ“Š TEST SET METRICS:\")\n",
                "print(\"=\"*60)\n",
                "print(f\"mAP@0.5:.......... {metrics.box.map50:.4f} ({metrics.box.map50*100:.2f}%)\")\n",
                "print(f\"mAP@0.5:0.95:..... {metrics.box.map:.4f} ({metrics.box.map*100:.2f}%)\")\n",
                "print(f\"Precision:........ {metrics.box.mp:.4f} ({metrics.box.mp*100:.2f}%)\")\n",
                "print(f\"Recall:........... {metrics.box.mr:.4f} ({metrics.box.mr*100:.2f}%)\")\n",
                "\n",
                "# Calculate F1 Score\n",
                "precision = metrics.box.mp\n",
                "recall = metrics.box.mr\n",
                "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
                "print(f\"\\nðŸŽ¯ F1 SCORE:....... {f1:.4f} ({f1*100:.2f}%)\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display training results\n",
                "from IPython.display import Image as IPImage, display\n",
                "\n",
                "results_dir = Path(PROJECT) / NAME\n",
                "\n",
                "print(\"\\nðŸ“ˆ TRAINING VISUALIZATIONS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Display training curves\n",
                "if (results_dir / 'results.png').exists():\n",
                "    print(\"\\n1ï¸âƒ£  Training Curves:\")\n",
                "    display(IPImage(filename=str(results_dir / 'results.png')))\n",
                "\n",
                "# Display confusion matrix\n",
                "conf_matrix_files = ['confusion_matrix_normalized.png', 'confusion_matrix.png']\n",
                "for cf in conf_matrix_files:\n",
                "    if (results_dir / cf).exists():\n",
                "        print(f\"\\n2ï¸âƒ£  Confusion Matrix:\")\n",
                "        display(IPImage(filename=str(results_dir / cf)))\n",
                "        break\n",
                "\n",
                "# Display PR curve\n",
                "if (results_dir / 'PR_curve.png').exists():\n",
                "    print(\"\\n3ï¸âƒ£  Precision-Recall Curve:\")\n",
                "    display(IPImage(filename=str(results_dir / 'PR_curve.png')))\n",
                "\n",
                "# Display F1 curve\n",
                "if (results_dir / 'F1_curve.png').exists():\n",
                "    print(\"\\n4ï¸âƒ£  F1 Confidence Curve:\")\n",
                "    display(IPImage(filename=str(results_dir / 'F1_curve.png')))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Detailed Per-Class Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Per-class metrics analysis\n",
                "# This provides detailed F1, Precision, Recall for each character\n",
                "\n",
                "print(\"\\nðŸ“‹ PER-CLASS PERFORMANCE METRICS:\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Get per-class metrics if available\n",
                "if hasattr(metrics.box, 'p') and hasattr(metrics.box, 'r'):\n",
                "    per_class_precision = metrics.box.p\n",
                "    per_class_recall = metrics.box.r\n",
                "    \n",
                "    # Create dataframe for better visualization\n",
                "    metrics_df = pd.DataFrame({\n",
                "        'Class': class_names[:len(per_class_precision)],\n",
                "        'Precision': per_class_precision,\n",
                "        'Recall': per_class_recall\n",
                "    })\n",
                "    \n",
                "    # Calculate F1 per class\n",
                "    metrics_df['F1'] = 2 * (metrics_df['Precision'] * metrics_df['Recall']) / \\\n",
                "                       (metrics_df['Precision'] + metrics_df['Recall'] + 1e-10)\n",
                "    \n",
                "    # Sort by F1 score\n",
                "    metrics_df_sorted = metrics_df.sort_values('F1', ascending=False)\n",
                "    \n",
                "    print(\"\\nTop 10 Best Performing Classes:\")\n",
                "    print(metrics_df_sorted.head(10).to_string(index=False))\n",
                "    \n",
                "    print(\"\\n\\nTop 10 Worst Performing Classes:\")\n",
                "    print(metrics_df_sorted.tail(10).to_string(index=False))\n",
                "    \n",
                "    # Overall statistics\n",
                "    print(\"\\n\\nðŸ“Š Per-Class Statistics:\")\n",
                "    print(\"=\"*60)\n",
                "    print(f\"Average F1:.........{metrics_df['F1'].mean():.4f}\")\n",
                "    print(f\"Std Dev F1:......... {metrics_df['F1'].std():.4f}\")\n",
                "    print(f\"Best F1 (Class {metrics_df_sorted.iloc[0]['Class']}):..... {metrics_df_sorted.iloc[0]['F1']:.4f}\")\n",
                "    print(f\"Worst F1 (Class {metrics_df_sorted.iloc[-1]['Class']}):..... {metrics_df_sorted.iloc[-1]['F1']:.4f}\")\n",
                "    print(\"=\"*60)\n",
                "else:\n",
                "    print(\"Per-class metrics not available in this YOLOv8 version.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Test OCR on Sample Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to reconstruct plate text from detections\n",
                "def reconstruct_plate_text(results, img_width):\n",
                "    \"\"\"\n",
                "    Reconstruct license plate text from character detections.\n",
                "    Sort by x-coordinate (left to right)\n",
                "    \"\"\"\n",
                "    boxes = results[0].boxes\n",
                "    \n",
                "    if len(boxes) == 0:\n",
                "        return \"\", 0.0\n",
                "    \n",
                "    # Extract detections\n",
                "    detections = []\n",
                "    for box in boxes:\n",
                "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
                "        conf = float(box.conf[0])\n",
                "        cls = int(box.cls[0])\n",
                "        x_center = (x1 + x2) / 2\n",
                "        detections.append((x_center, cls, conf))\n",
                "    \n",
                "    # Sort by x-coordinate (left to right)\n",
                "    detections.sort(key=lambda x: x[0])\n",
                "    \n",
                "    # Build text\n",
                "    text = ''.join([class_names[cls] for _, cls, _ in detections])\n",
                "    avg_conf = np.mean([conf for _, _, conf in detections])\n",
                "    \n",
                "    return text, avg_conf"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test on random samples from test set\n",
                "fig, axes = plt.subplots(3, 3, figsize=(18, 18))\n",
                "axes = axes.ravel()\n",
                "\n",
                "sample_imgs = np.random.choice(test_images, min(9, len(test_images)), replace=False)\n",
                "\n",
                "correct_predictions = 0\n",
                "total_predictions = 0\n",
                "\n",
                "for idx, img_path in enumerate(sample_imgs):\n",
                "    img = Image.open(img_path)\n",
                "    img_w, img_h = img.size\n",
                "    \n",
                "    # Run inference\n",
                "    results = model(img, conf=0.25, verbose=False)\n",
                "    \n",
                "    # Reconstruct text\n",
                "    plate_text, confidence = reconstruct_plate_text(results, img_w)\n",
                "    \n",
                "    # Render predictions\n",
                "    annotated = results[0].plot()\n",
                "    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    axes[idx].imshow(annotated_rgb)\n",
                "    axes[idx].axis('off')\n",
                "    \n",
                "    title_color = 'green' if confidence > 0.7 else 'orange' if confidence > 0.5 else 'red'\n",
                "    axes[idx].set_title(\n",
                "        f'Predicted: \"{plate_text}\"\\nConf: {confidence:.2f}', \n",
                "        fontsize=11, \n",
                "        fontweight='bold',\n",
                "        color=title_color\n",
                "    )\n",
                "    \n",
                "    total_predictions += 1\n",
                "    if confidence > 0.7:\n",
                "        correct_predictions += 1\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.suptitle('Test Set OCR Results', fontsize=16, y=1.01, weight='bold')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nHigh Confidence Predictions (> 0.7): {correct_predictions}/{total_predictions} ({correct_predictions/total_predictions*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Inference Speed Benchmark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Benchmark inference speed\n",
                "test_img = str(test_images[0])\n",
                "img = Image.open(test_img)\n",
                "\n",
                "# Warmup\n",
                "print(\"Warming up model...\")\n",
                "for _ in range(10):\n",
                "    _ = model(img, verbose=False)\n",
                "\n",
                "# Benchmark\n",
                "num_runs = 100\n",
                "print(f\"Running {num_runs} inference iterations...\")\n",
                "times = []\n",
                "for _ in range(num_runs):\n",
                "    start = time.time()\n",
                "    results = model(img, verbose=False)\n",
                "    times.append(time.time() - start)\n",
                "\n",
                "times = np.array(times) * 1000  # Convert to ms\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"âš¡ OCR INFERENCE SPEED BENCHMARK\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Runs:...................... {num_runs}\")\n",
                "print(f\"Mean:...................... {times.mean():.2f} ms\")\n",
                "print(f\"Median:.................... {np.median(times):.2f} ms\")\n",
                "print(f\"Std Dev:................... {times.std():.2f} ms\")\n",
                "print(f\"Min:....................... {times.min():.2f} ms\")\n",
                "print(f\"Max:....................... {times.max():.2f} ms\")\n",
                "print(f\"FPS (mean):................ {1000/times.mean():.2f}\")\n",
                "print(f\"\\nThis is fast enough for server-side processing! âœ“\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Plot distribution\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.hist(times, bins=30, color='lightcoral', edgecolor='black')\n",
                "plt.axvline(times.mean(), color='red', linestyle='--', label=f'Mean: {times.mean():.2f} ms')\n",
                "plt.axvline(np.median(times), color='green', linestyle='--', label=f'Median: {np.median(times):.2f} ms')\n",
                "plt.xlabel('Inference Time (ms)')\n",
                "plt.ylabel('Frequency')\n",
                "plt.title('OCR Inference Time Distribution')\n",
                "plt.legend()\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Export Model for Deployment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create export directory\n",
                "export_dir = Path('../models/recognition') if not IN_COLAB else Path('/content/models_export/recognition')\n",
                "export_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(f\"âœ“ Export directory: {export_dir.absolute()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to ONNX\n",
                "print(\"Exporting to ONNX format...\")\n",
                "onnx_path = model.export(format='onnx', imgsz=IMG_SIZE, simplify=True)\n",
                "shutil.copy(onnx_path, export_dir / 'license_plate_recognition.onnx')\n",
                "print(f\"âœ“ ONNX model exported to: {export_dir / 'license_plate_recognition.onnx'}\")\n",
                "print(f\"  Size: {os.path.getsize(export_dir / 'license_plate_recognition.onnx') / 1024 / 1024:.2f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copy PyTorch weights\n",
                "shutil.copy(best_model_path, export_dir / 'license_plate_recognition.pt')\n",
                "print(f\"âœ“ PyTorch weights saved to: {export_dir / 'license_plate_recognition.pt'}\")\n",
                "print(f\"  Size: {os.path.getsize(export_dir / 'license_plate_recognition.pt') / 1024 / 1024:.2f} MB\")\n",
                "\n",
                "# Also save class names\n",
                "with open(export_dir / 'classes.names', 'w') as f:\n",
                "    f.write('\\n'.join(class_names))\n",
                "print(f\"âœ“ Class names saved to: {export_dir / 'classes.names'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download models (for Colab)\n",
                "if IN_COLAB:\n",
                "    from google.colab import files\n",
                "    \n",
                "    print(\"\\nðŸ“¥ Download models:\")\n",
                "    \n",
                "    print(\"Downloading PyTorch model...\")\n",
                "    files.download(str(export_dir / 'license_plate_recognition.pt'))\n",
                "    \n",
                "    print(\"Downloading ONNX model...\")\n",
                "    files.download(str(export_dir / 'license_plate_recognition.onnx'))\n",
                "    \n",
                "    print(\"Downloading class names...\")\n",
                "    files.download(str(export_dir / 'classes.names'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Summary & Final Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"âœ… LICENSE PLATE RECOGNITION (OCR) TRAINING COMPLETE\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nðŸ”§ Model Configuration:\")\n",
                "print(f\"  Model:................ {MODEL}\")\n",
                "print(f\"  Training epochs:...... {EPOCHS}\")\n",
                "print(f\"  Number of classes:.... {len(class_names)} (0-9, A-Z)\")\n",
                "print(f\"  Best weights:......... {best_model_path}\")\n",
                "print(f\"\\nðŸ“¦ Exported Models:\")\n",
                "print(f\"  ONNX:................. {export_dir / 'license_plate_recognition.onnx'}\")\n",
                "print(f\"  PyTorch:.............. {export_dir / 'license_plate_recognition.pt'}\")\n",
                "print(f\"  Classes:.............. {export_dir / 'classes.names'}\")\n",
                "print(f\"\\nðŸŽ¯ Final Test Set Metrics:\")\n",
                "print(f\"  F1 Score:............. {f1:.4f} ({f1*100:.2f}%)\")\n",
                "print(f\"  Precision:............ {precision:.4f} ({precision*100:.2f}%)\")\n",
                "print(f\"  Recall:............... {recall:.4f} ({recall*100:.2f}%)\")\n",
                "print(f\"  mAP@0.5:.............. {metrics.box.map50:.4f} ({metrics.box.map50*100:.2f}%)\")\n",
                "print(f\"  mAP@0.5:0.95:......... {metrics.box.map:.4f} ({metrics.box.map*100:.2f}%)\")\n",
                "print(f\"\\nâš¡ Performance:\")\n",
                "print(f\"  Avg Inference:........ {times.mean():.2f} ms\")\n",
                "print(f\"  FPS:.................. {1000/times.mean():.2f}\")\n",
                "print(f\"\\nðŸ“± Next Steps:\")\n",
                "print(f\"  1. Download models (PyTorch & ONNX)\")\n",
                "print(f\"  2. Deploy to server (backend/python-service/)\")\n",
                "print(f\"  3. Integrate dengan edge device (Raspberry Pi)\")\n",
                "print(f\"  4. Test end-to-end parking entry system\")\n",
                "print(f\"  5. Fine-tune on your specific camera setup if needed\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Save summary to file\n",
                "summary_file = export_dir / 'training_summary.txt'\n",
                "with open(summary_file, 'w') as f:\n",
                "    f.write(f\"License Plate Recognition Training Summary\\n\")\n",
                "    f.write(f\"=\"*60 + \"\\n\")\n",
                "    f.write(f\"Model: {MODEL}\\n\")\n",
                "    f.write(f\"Epochs: {EPOCHS}\\n\")\n",
                "    f.write(f\"Classes: {len(class_names)}\\n\")\n",
                "    f.write(f\"\\nTest Set Metrics:\\n\")\n",
                "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
                "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
                "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
                "    f.write(f\"mAP@0.5: {metrics.box.map50:.4f}\\n\")\n",
                "    f.write(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\\n\")\n",
                "    f.write(f\"\\nInference Speed: {times.mean():.2f} ms\\n\")\n",
                "\n",
                "print(f\"\\nâœ“ Training summary saved to: {summary_file}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 4
}