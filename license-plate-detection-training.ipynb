{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# License Plate Detection Training - YOLOv5\n",
        "\n",
        "Training model untuk deteksi plat nomor di Raspberry Pi 2 (edge device).\n",
        "\n",
        "**Dataset**: Indonesian License Plate Dataset (~2000 images)\n",
        "\n",
        "**Model**: YOLOv5 nano/small (optimized untuk edge device dengan resource terbatas)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_REPO/license-plate-detection-training.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Google Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if running on Google Colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"âœ“ Running on Google Colab\")\n",
        "    # Check GPU\n",
        "    !nvidia-smi\n",
        "else:\n",
        "    print(\"âœ“ Running locally\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q onnx onnxruntime kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
        "import kagglehub\n",
        "\n",
        "print(\"Environment setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download Dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset using kagglehub\n",
        "print(\"Downloading Indonesian License Plate Dataset from Kaggle...\")\n",
        "path = kagglehub.dataset_download(\"juanthomaswijaya/indonesian-license-plate-dataset\")\n",
        "\n",
        "print(f\"âœ“ Dataset downloaded to: {path}\")\n",
        "DATASET_ROOT = Path(path)\n",
        "\n",
        "# List contents\n",
        "print(\"\\nDataset contents:\")\n",
        "for item in DATASET_ROOT.iterdir():\n",
        "    print(f\"  {item.name}\")\n",
        "\n",
        "# Find the correct DETECTION dataset folder\n",
        "# The Kaggle dataset has 2 folders:\n",
        "#   1. \"Indonesian License Plate Dataset\" - for DETECTION\n",
        "#   2. \"Indonesian License Plate Recognition Dataset\" - for RECOGNITION (OCR)\n",
        "detection_dataset_candidates = [\n",
        "    DATASET_ROOT / 'Indonesian License Plate Dataset',\n",
        "    DATASET_ROOT / 'indonesian-license-plate-dataset'\n",
        "]\n",
        "\n",
        "# Also search recursively in case of nested structure\n",
        "detection_dataset_candidates.extend(list(DATASET_ROOT.glob('**/Indonesian License Plate Dataset')))\n",
        "\n",
        "found = False\n",
        "for candidate in detection_dataset_candidates:\n",
        "    if candidate.exists() and (candidate / 'images').exists():\n",
        "        DATASET_ROOT = candidate\n",
        "        found = True\n",
        "        print(f\"\\nâœ“ Found DETECTION dataset at: {DATASET_ROOT}\")\n",
        "        break\n",
        "\n",
        "if not found:\n",
        "    print(\"\\nâš ï¸  DETECTION dataset folder not found automatically.\")\n",
        "    print(\"Available directories with 'images':\")\n",
        "    for item in Path(path).rglob('images'):\n",
        "        if item.is_dir():\n",
        "            print(f\"  {item.parent} -> {item}\")\n",
        "    \n",
        "    # Try to auto-select if only one images dir found\n",
        "    images_dirs = list(Path(path).rglob('images'))\n",
        "    if len(images_dirs) > 0:\n",
        "        DATASET_ROOT = images_dirs[0].parent\n",
        "        print(f\"\\nâœ“ Auto-selected: {DATASET_ROOT}\")\n",
        "    else:\n",
        "        print(\"\\nâŒ Please manually set DATASET_ROOT in the next cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Preparation & Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find images and labels directories\n",
        "IMAGES_DIR = DATASET_ROOT / 'images'\n",
        "LABELS_DIR = DATASET_ROOT / 'labels'\n",
        "\n",
        "# Verify dataset structure\n",
        "print(f\"Dataset root exists: {DATASET_ROOT.exists()}\")\n",
        "print(f\"Images dir exists: {IMAGES_DIR.exists()}\")\n",
        "print(f\"Labels dir exists: {LABELS_DIR.exists()}\")\n",
        "\n",
        "# Count files\n",
        "train_images = list((IMAGES_DIR / 'train').glob('*.jpg')) + list((IMAGES_DIR / 'train').glob('*.png'))\n",
        "val_images = list((IMAGES_DIR / 'val').glob('*.jpg')) + list((IMAGES_DIR / 'val').glob('*.png'))\n",
        "test_images = list((IMAGES_DIR / 'test').glob('*.jpg')) + list((IMAGES_DIR / 'test').glob('*.png'))\n",
        "\n",
        "print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"Train images: {len(train_images):>6}\")\n",
        "print(f\"Val images:   {len(val_images):>6}\")\n",
        "print(f\"Test images:  {len(test_images):>6}\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"Total:        {len(train_images) + len(val_images) + len(test_images):>6}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample images with annotations\n",
        "def visualize_sample(image_paths, label_dir, num_samples=4):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    samples = np.random.choice(image_paths, min(num_samples, len(image_paths)), replace=False)\n",
        "    \n",
        "    for idx, img_file in enumerate(samples):\n",
        "        img = Image.open(img_file)\n",
        "        img_w, img_h = img.size\n",
        "        \n",
        "        # Read corresponding label\n",
        "        label_file = label_dir / (img_file.stem + '.txt')\n",
        "        \n",
        "        axes[idx].imshow(img)\n",
        "        \n",
        "        # Draw bounding boxes\n",
        "        if label_file.exists():\n",
        "            with open(label_file, 'r') as f:\n",
        "                for line in f.readlines():\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) >= 5:\n",
        "                        class_id, x_center, y_center, width, height = map(float, parts[:5])\n",
        "                        \n",
        "                        # Convert YOLO format to pixel coordinates\n",
        "                        x_center *= img_w\n",
        "                        y_center *= img_h\n",
        "                        width *= img_w\n",
        "                        height *= img_h\n",
        "                        \n",
        "                        x1 = x_center - width / 2\n",
        "                        y1 = y_center - height / 2\n",
        "                        \n",
        "                        from matplotlib.patches import Rectangle\n",
        "                        rect = Rectangle((x1, y1), width, height, linewidth=2, \n",
        "                                       edgecolor='red', facecolor='none')\n",
        "                        axes[idx].add_patch(rect)\n",
        "                        axes[idx].text(x1, y1-5, 'License Plate', color='red', \n",
        "                                     fontsize=10, weight='bold', \n",
        "                                     bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "        \n",
        "        axes[idx].axis('off')\n",
        "        axes[idx].set_title(f'Sample {idx+1}: {img_file.name}', fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize training samples\n",
        "print(\"ðŸ“¸ Training Data Samples:\")\n",
        "visualize_sample(train_images, LABELS_DIR / 'train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create YOLOv5 Dataset Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataset.yaml for YOLOv5\n",
        "dataset_yaml = {\n",
        "    'path': str(DATASET_ROOT.absolute()),\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'test': 'images/test',\n",
        "    'nc': 1,  # number of classes\n",
        "    'names': ['license_plate']\n",
        "}\n",
        "\n",
        "yaml_path = 'license_plate_detection.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(dataset_yaml, f)\n",
        "\n",
        "print(f\"âœ“ Dataset config saved to: {yaml_path}\")\n",
        "print(\"\\nContent:\")\n",
        "with open(yaml_path, 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train YOLOv5 Nano (Optimized for Raspberry Pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "MODEL = 'yolov5n'  # nano model (lightest, ~2MB)\n",
        "# Alternative: yolov5s (small, ~7MB) jika butuh akurasi lebih tinggi\n",
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 16 if IN_COLAB else 8  # Larger batch for GPU\n",
        "IMG_SIZE = 640\n",
        "PROJECT = 'runs/train'\n",
        "NAME = 'license_plate_detection'\n",
        "\n",
        "print(f\"ðŸ”§ Training Configuration:\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"Model:       {MODEL}\")\n",
        "print(f\"Epochs:      {EPOCHS}\")\n",
        "print(f\"Batch size:  {BATCH_SIZE}\")\n",
        "print(f\"Image size:  {IMG_SIZE}\")\n",
        "print(f\"Device:      {'GPU (Colab)' if IN_COLAB else 'CPU/GPU'}\")\n",
        "print(f\"{'='*40}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "!python train.py \\\n",
        "    --img {IMG_SIZE} \\\n",
        "    --batch {BATCH_SIZE} \\\n",
        "    --epochs {EPOCHS} \\\n",
        "    --data {yaml_path} \\\n",
        "    --weights {MODEL}.pt \\\n",
        "    --project {PROJECT} \\\n",
        "    --name {NAME} \\\n",
        "    --cache \\\n",
        "    --patience 20 \\\n",
        "    --save-period 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Comprehensive Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model path\n",
        "WEIGHTS_PATH = f'{PROJECT}/{NAME}/weights/best.pt'\n",
        "print(f\"ðŸ“¦ Loading best model from: {WEIGHTS_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate on TEST set dengan detailed metrics\n",
        "print(\"\\nðŸ§ª Testing on TEST SET...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python val.py \\\n",
        "    --weights {WEIGHTS_PATH} \\\n",
        "    --data {yaml_path} \\\n",
        "    --img {IMG_SIZE} \\\n",
        "    --task test \\\n",
        "    --save-txt \\\n",
        "    --save-conf \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse validation results and calculate comprehensive metrics\n",
        "import json\n",
        "\n",
        "results_dir = Path(f'{PROJECT}/{NAME}')\n",
        "\n",
        "# Read results from CSV if available\n",
        "results_csv = results_dir / 'results.csv'\n",
        "if results_csv.exists():\n",
        "    df_results = pd.read_csv(results_csv)\n",
        "    df_results.columns = df_results.columns.str.strip()\n",
        "    \n",
        "    print(\"\\nðŸ“Š TRAINING METRICS SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Get final epoch metrics\n",
        "    final_metrics = df_results.iloc[-1]\n",
        "    \n",
        "    # Print comprehensive metrics\n",
        "    metrics_to_show = {\n",
        "        'Precision': 'metrics/precision',\n",
        "        'Recall': 'metrics/recall',\n",
        "        'mAP@0.5': 'metrics/mAP_0.5',\n",
        "        'mAP@0.5:0.95': 'metrics/mAP_0.5:0.95',\n",
        "        'Train Loss (box)': 'train/box_loss',\n",
        "        'Train Loss (obj)': 'train/obj_loss',\n",
        "        'Val Loss (box)': 'val/box_loss',\n",
        "        'Val Loss (obj)': 'val/obj_loss'\n",
        "    }\n",
        "    \n",
        "    for metric_name, col_name in metrics_to_show.items():\n",
        "        if col_name in final_metrics:\n",
        "            value = final_metrics[col_name]\n",
        "            print(f\"{metric_name:.<30} {value:.4f}\")\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Calculate F1 Score\n",
        "    if 'metrics/precision' in final_metrics and 'metrics/recall' in final_metrics:\n",
        "        precision = final_metrics['metrics/precision']\n",
        "        recall = final_metrics['metrics/recall']\n",
        "        \n",
        "        if precision + recall > 0:\n",
        "            f1_score_val = 2 * (precision * recall) / (precision + recall)\n",
        "            print(f\"\\nðŸŽ¯ F1 SCORE: {f1_score_val:.4f}\")\n",
        "            print(\"=\"*60)\n",
        "else:\n",
        "    print(\"âš ï¸  Results CSV not found. Metrics will be shown from validation output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize training results\n",
        "from IPython.display import Image as IPImage, display\n",
        "\n",
        "print(\"\\nðŸ“ˆ TRAINING VISUALIZATIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Display training curves\n",
        "if (results_dir / 'results.png').exists():\n",
        "    print(\"\\n1ï¸âƒ£  Training Curves:\")\n",
        "    display(IPImage(filename=str(results_dir / 'results.png')))\n",
        "\n",
        "# Display confusion matrix\n",
        "if (results_dir / 'confusion_matrix.png').exists():\n",
        "    print(\"\\n2ï¸âƒ£  Confusion Matrix:\")\n",
        "    display(IPImage(filename=str(results_dir / 'confusion_matrix.png')))\n",
        "\n",
        "# Display PR curve\n",
        "if (results_dir / 'PR_curve.png').exists():\n",
        "    print(\"\\n3ï¸âƒ£  Precision-Recall Curve:\")\n",
        "    display(IPImage(filename=str(results_dir / 'PR_curve.png')))\n",
        "\n",
        "# Display F1 curve\n",
        "if (results_dir / 'F1_curve.png').exists():\n",
        "    print(\"\\n4ï¸âƒ£  F1 Confidence Curve:\")\n",
        "    display(IPImage(filename=str(results_dir / 'F1_curve.png')))\n",
        "\n",
        "# Display validation predictions\n",
        "if (results_dir / 'val_batch0_pred.jpg').exists():\n",
        "    print(\"\\n5ï¸âƒ£  Validation Predictions (Batch 0):\")\n",
        "    display(IPImage(filename=str(results_dir / 'val_batch0_pred.jpg')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Detailed Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "# Load model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path=WEIGHTS_PATH)\n",
        "model.conf = 0.5  # Confidence threshold\n",
        "model.iou = 0.45  # NMS IOU threshold\n",
        "\n",
        "print(\"âœ“ Model loaded for inference\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test on all test images and collect detailed metrics\n",
        "print(\"\\nðŸ§ª Running inference on test set...\")\n",
        "\n",
        "test_results = {\n",
        "    'true_positives': 0,\n",
        "    'false_positives': 0,\n",
        "    'false_negatives': 0,\n",
        "    'inference_times': [],\n",
        "    'confidences': []\n",
        "}\n",
        "\n",
        "for img_path in test_images[:50]:  # Test on subset for speed\n",
        "    img = Image.open(img_path)\n",
        "    \n",
        "    # Ground truth\n",
        "    label_file = LABELS_DIR / 'test' / (img_path.stem + '.txt')\n",
        "    has_ground_truth = label_file.exists() and os.path.getsize(label_file) > 0\n",
        "    \n",
        "    # Inference\n",
        "    start = time.time()\n",
        "    results = model(img)\n",
        "    inference_time = time.time() - start\n",
        "    test_results['inference_times'].append(inference_time)\n",
        "    \n",
        "    # Count detections\n",
        "    detections = results.pandas().xyxy[0]\n",
        "    num_detections = len(detections)\n",
        "    \n",
        "    if num_detections > 0:\n",
        "        test_results['confidences'].extend(detections['confidence'].tolist())\n",
        "    \n",
        "    # Simple TP/FP/FN calculation\n",
        "    if has_ground_truth and num_detections > 0:\n",
        "        test_results['true_positives'] += 1\n",
        "    elif not has_ground_truth and num_detections > 0:\n",
        "        test_results['false_positives'] += 1\n",
        "    elif has_ground_truth and num_detections == 0:\n",
        "        test_results['false_negatives'] += 1\n",
        "\n",
        "print(\"âœ“ Inference complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate comprehensive test metrics\n",
        "tp = test_results['true_positives']\n",
        "fp = test_results['false_positives']\n",
        "fn = test_results['false_negatives']\n",
        "\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "avg_inference = np.mean(test_results['inference_times']) * 1000  # ms\n",
        "avg_conf = np.mean(test_results['confidences']) if test_results['confidences'] else 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š COMPREHENSIVE TEST SET METRICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nðŸŽ¯ Detection Performance:\")\n",
        "print(f\"  True Positives:............ {tp}\")\n",
        "print(f\"  False Positives:........... {fp}\")\n",
        "print(f\"  False Negatives:........... {fn}\")\n",
        "print(f\"\\nðŸ“ˆ Classification Metrics:\")\n",
        "print(f\"  Precision:................. {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"  Recall:.................... {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"  F1 Score:.................. {f1:.4f} ({f1*100:.2f}%)\")\n",
        "print(f\"\\nâš¡ Performance Metrics:\")\n",
        "print(f\"  Avg Inference Time:........ {avg_inference:.2f} ms\")\n",
        "print(f\"  FPS:...................... {1000/avg_inference:.2f}\")\n",
        "print(f\"  Avg Confidence:............ {avg_conf:.4f} ({avg_conf*100:.2f}%)\")\n",
        "print(f\"\\nðŸ“± Raspberry Pi 2 Estimate:\")\n",
        "print(f\"  Expected FPS:.............. 1-3 FPS\")\n",
        "print(f\"  Expected Latency:.......... 500-1000 ms\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Inference Speed Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed speed benchmark\n",
        "test_img = str(test_images[0])\n",
        "img = Image.open(test_img)\n",
        "\n",
        "# Warmup\n",
        "print(\"Warming up model...\")\n",
        "for _ in range(10):\n",
        "    _ = model(img)\n",
        "\n",
        "# Benchmark\n",
        "num_runs = 100\n",
        "print(f\"Running {num_runs} inference iterations...\")\n",
        "times = []\n",
        "for _ in range(num_runs):\n",
        "    start = time.time()\n",
        "    results = model(img)\n",
        "    times.append(time.time() - start)\n",
        "\n",
        "times = np.array(times) * 1000  # Convert to ms\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âš¡ INFERENCE SPEED BENCHMARK\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Runs:...................... {num_runs}\")\n",
        "print(f\"Mean:...................... {times.mean():.2f} ms\")\n",
        "print(f\"Median:.................... {np.median(times):.2f} ms\")\n",
        "print(f\"Std Dev:................... {times.std():.2f} ms\")\n",
        "print(f\"Min:....................... {times.min():.2f} ms\")\n",
        "print(f\"Max:....................... {times.max():.2f} ms\")\n",
        "print(f\"FPS (mean):................ {1000/times.mean():.2f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Plot distribution\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(times, bins=30, color='skyblue', edgecolor='black')\n",
        "plt.axvline(times.mean(), color='red', linestyle='--', label=f'Mean: {times.mean():.2f} ms')\n",
        "plt.axvline(np.median(times), color='green', linestyle='--', label=f'Median: {np.median(times):.2f} ms')\n",
        "plt.xlabel('Inference Time (ms)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Inference Time Distribution')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Visual Test Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test detection on sample images\n",
        "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
        "axes = axes.ravel()\n",
        "\n",
        "sample_imgs = np.random.choice(test_images, min(9, len(test_images)), replace=False)\n",
        "\n",
        "for idx, img_path in enumerate(sample_imgs):\n",
        "    img = Image.open(img_path)\n",
        "    results = model(img)\n",
        "    \n",
        "    # Render results\n",
        "    rendered = results.render()[0]\n",
        "    \n",
        "    # Get detection info\n",
        "    detections = results.pandas().xyxy[0]\n",
        "    num_det = len(detections)\n",
        "    avg_conf = detections['confidence'].mean() if num_det > 0 else 0\n",
        "    \n",
        "    axes[idx].imshow(rendered)\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(\n",
        "        f'Detections: {num_det} | Conf: {avg_conf:.2f}',\n",
        "        fontsize=10,\n",
        "        color='green' if num_det > 0 else 'red'\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Test Set Detection Results', fontsize=16, y=1.01, weight='bold')\n",
        "plt.show()\n",
        "\n",
        "# Print detection details for first sample\n",
        "if len(sample_imgs) > 0:\n",
        "    print(\"\\nðŸ“‹ Sample Detection Details:\")\n",
        "    print(\"=\"*60)\n",
        "    results = model(Image.open(sample_imgs[0]))\n",
        "    print(results.pandas().xyxy[0].to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Export Model for Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create export directory\n",
        "export_dir = Path('../models/detection') if not IN_COLAB else Path('/content/models_export/detection')\n",
        "export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"âœ“ Export directory: {export_dir.absolute()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to ONNX (recommended for cross-platform)\n",
        "print(\"Exporting to ONNX format...\")\n",
        "!python export.py \\\n",
        "    --weights {WEIGHTS_PATH} \\\n",
        "    --include onnx \\\n",
        "    --img {IMG_SIZE} \\\n",
        "    --simplify\n",
        "\n",
        "# Copy exported model\n",
        "onnx_path = Path(WEIGHTS_PATH).parent / 'best.onnx'\n",
        "if onnx_path.exists():\n",
        "    shutil.copy(onnx_path, export_dir / 'license_plate_detection.onnx')\n",
        "    print(f\"âœ“ ONNX model exported to: {export_dir / 'license_plate_detection.onnx'}\")\n",
        "    print(f\"  Size: {os.path.getsize(export_dir / 'license_plate_detection.onnx') / 1024 / 1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Also copy PyTorch weights\n",
        "shutil.copy(WEIGHTS_PATH, export_dir / 'license_plate_detection.pt')\n",
        "print(f\"âœ“ PyTorch weights saved to: {export_dir / 'license_plate_detection.pt'}\")\n",
        "print(f\"  Size: {os.path.getsize(export_dir / 'license_plate_detection.pt') / 1024 / 1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download models (for Colab)\n",
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    \n",
        "    print(\"\\nðŸ“¥ Download models:\")\n",
        "    print(\"Click to download ONNX model (for Raspberry Pi)\")\n",
        "    files.download(str(export_dir / 'license_plate_detection.onnx'))\n",
        "    \n",
        "    print(\"Click to download PyTorch model\")\n",
        "    files.download(str(export_dir / 'license_plate_detection.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary & Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… LICENSE PLATE DETECTION TRAINING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nModel: {MODEL}\")\n",
        "print(f\"Training epochs: {EPOCHS}\")\n",
        "print(f\"Best weights: {WEIGHTS_PATH}\")\n",
        "print(f\"\\nðŸ“¦ Exported models:\")\n",
        "print(f\"  ONNX:      {export_dir / 'license_plate_detection.onnx'}\")\n",
        "print(f\"  PyTorch:   {export_dir / 'license_plate_detection.pt'}\")\n",
        "print(f\"\\nðŸŽ¯ Final Metrics (Test Set):\")\n",
        "print(f\"  F1 Score:  {f1:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall:    {recall:.4f}\")\n",
        "print(f\"\\nâš¡ Performance:\")\n",
        "print(f\"  Inference: {avg_inference:.2f} ms\")\n",
        "print(f\"  FPS:       {1000/avg_inference:.2f}\")\n",
        "print(f\"\\nðŸ“± Next Steps:\")\n",
        "print(f\"  1. Download ONNX model\")\n",
        "print(f\"  2. Deploy to Raspberry Pi 2\")\n",
        "print(f\"  3. Test real-time inference dengan camera\")\n",
        "print(f\"  4. Train recognition model (next notebook)\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
